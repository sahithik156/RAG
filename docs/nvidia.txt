Nvidia Corporation[a] (/?n'v?di?/ en-VID-ee-?) is an American technology company headquartered in Santa Clara, California. Founded in 1993 by Jensen Huang, Chris Malachowsky, and Curtis Priem, it develops graphics processing units (GPUs), systems on chips (SoCs), and application programming interfaces (APIs) for data science, high-performance computing, video games, and mobile and automotive applications.[5][6] Nvidia has been described as a Big Tech company.

Originally focused on GPUs for video gaming, Nvidia broadened their use into other markets, including artificial intelligence (AI), professional visualization, and supercomputing. The company's product lines include GeForce GPUs for gaming and creative workloads, and professional GPUs for edge computing, scientific research, and industrial applications. As of the first quarter of 2025, Nvidia held a 92% share of the discrete desktop and laptop GPU market.[7][8]

In the early 2000s, the company invested over a billion dollars to develop CUDA, a software platform and API that enabled GPUs to run massively parallel programs for a broad range of compute-intensive applications.[9][10][11] As a result, as of 2025, Nvidia controlled more than 80% of the market for GPUs used in training and deploying AI models,[9] and provided chips for over 75% of the world's TOP500 supercomputers.[1] The company has also expanded into gaming hardware and services, with products such as the Shield Portable, Shield Tablet, and Shield TV, and operates the GeForce Now cloud gaming service.[12] Furthermore, it has developed the Tegra line of mobile processors for smartphones, tablets, and automotive infotainment systems.[13][14][15]

In 2023, Nvidia became the seventh U.S. company to reach a US$1 trillion valuation.[16] It became the first company in the world to surpass US$4 trillion[17][18] and US$5 trillion[19] milestones in market capitalization in 2025, driven by rising global demand for AI datacenter hardware in the midst of the AI boom. For its strength, size and market capitalization, Nvidia has been selected to be one of Bloomberg's "Magnificent Seven", the seven biggest companies on the stock market in these regards.[20]

History
Founding

The Denny's roadside diner in San Jose, California, where Nvidia's three co-founders agreed to start the company in late 1992

Nvidia's former headquarters which was home to the company through most of its pre-AI period (still in use)

Aerial view of Endeavor, the first of the two new Nvidia headquarters buildings, in Santa Clara, California, in 2017

Entrance of Endeavor headquarters building in 2018
Nvidia was founded on April 5, 1993,[21][22][23] by Jensen Huang, a Taiwanese-American electrical engineer who was previously the director of CoreWare at LSI Logic and a microprocessor designer at AMD; Chris Malachowsky, an engineer who worked at Sun Microsystems; and Curtis Priem, who was previously a senior staff engineer and graphics chip designer at IBM and Sun Microsystems.[24][25] In late 1992, the three men agreed to start the company in a meeting at a Denny's roadside diner on Berryessa Road in East San Jose.[26][27][28][29]

At the time, Malachowsky and Priem were frustrated with Sun's management and were looking to leave, but Huang was on "firmer ground",[30] in that he was already running his own division at LSI.[27] The three co-founders discussed a vision of the future which was so compelling that Huang decided to leave LSI[30] and become the chief executive officer of their new startup.[27]

The three co-founders envisioned graphics-based processing as the best trajectory for tackling challenges that had eluded general-purpose computing methods.[30] As Huang later explained: "We also observed that video games were simultaneously one of the most computationally challenging problems and would have incredibly high sales volume. Those two conditions don't happen very often. Video games was our killer app -- a flywheel to reach large markets funding huge R&D to solve massive computational problems."[30]

The first problem was who would quit first. Huang's wife, Lori, did not want him to resign from LSI unless Malachowsky resigned from Sun at the same time, and Malachowsky's wife, Melody, felt the same way about Huang.[31] Priem broke that deadlock by resigning first from Sun, effective December 31, 1992.[31] According to Priem, this put pressure on Huang and Malachowsky to not leave him to "flail alone", so they gave notice too.[32] Huang left LSI and "officially joined Priem on February 17", which was also Huang's 30th birthday, while Malachowsky left Sun in early March.[32] In early 1993, the three founders began working together on their new startup in Priem's townhouse in Fremont, California.[33]

With $40,000 in the bank, the company was born.[30] The company subsequently received $20 million of venture capital funding from Sequoia Capital, Sutter Hill Ventures, and others.[34]

During the late 1990s, Nvidia was one of 70 startup companies pursuing the idea that graphics acceleration for video games was the path to the future.[26] Only two survived: Nvidia and ATI Technologies, the latter of which merged into AMD.[26]

Nvidia initially had no name.[35] Priem's first idea was "Primal Graphics", a syllabic abbreviation of two of the founders' last names, but that left out Huang.[35] They soon discovered it was impossible to create a workable name with syllables from all three founders' names, after considering "Huaprimal", "Prihuamal", "Malluapri", etc.[35] The next idea came from Priem's idea for the name of Nvidia's first product.[35] Priem originally wanted to call it the "GXNV", as in the "next version" of the GX graphics chips which he had worked on at Sun.[33] Then Huang told Priem to "drop the GX", resulting in the name "NV".[33] Priem made a list of words with the letters "NV" in them.[35] At one point, Malachowsky and Priem wanted to call the company NVision, but that name was already taken by a manufacturer of toilet paper.[27] Both Priem[35] and Huang have taken credit for coming up with the name Nvidia,[27] from "invidia", the Latin word for "envy".[30]

After the company outgrew Priem's townhouse, its original headquarters office was in Sunnyvale, California.[30]

First graphics accelerator
Nvidia's first graphics accelerator, the NV1, was designed to process quadrilateral primitives (forward texture mapping), a feature that set it apart from competitors, who preferred triangle primitives.[27] However, when Microsoft introduced the DirectX platform, it chose not to support any other graphics software and announced that its Direct3D API would exclusively support triangles.[27][36] As a result, the NV1 failed to gain traction in the market.[37]

Nvidia had also entered into a partnership with Sega to supply the graphics chip for the Dreamcast console and worked on the project for about a year. However, Nvidia's technology was already lagging behind competitors. This placed the company in a difficult position: continue working on a chip that was likely doomed to fail or abandon the project, risking financial collapse.[38]

In a pivotal moment, Sega's president, Shoichiro Irimajiri, visited Huang in person to inform him that Sega had decided to choose another vendor for the Dreamcast. However, Irimajiri believed in Nvidia's potential and persuaded Sega's management to invest $5 million into the company. Huang later reflected that this funding was all that kept Nvidia afloat, and that Irimajiri's "understanding and generosity gave us six months to live".[38]

In 1996, Huang laid off more than half of Nvidia's employees--reducing headcount from 100 to 40--and focused the company's remaining resources on developing a graphics accelerator product optimized for processing triangle primitives: the RIVA 128.[27][36] By the time the RIVA 128 was released in August 1997, Nvidia had only enough money left for one month's payroll.[27] The sense of impending failure became so pervasive that it gave rise to Nvidia's unofficial company motto: "Our company is thirty days from going out of business."[27] Huang began internal presentations to Nvidia staff with those words for many years.[27]

Nvidia sold about a million RIVA 128 units within four months,[27] and used the revenue to fund development of its next generation of products.[36] In 1998, the release of the RIVA TNT helped solidify Nvidia's reputation as a leader in graphics technology.[39]

Public company
Nvidia went public on January 22, 1999.[40][41][42] Investing in Nvidia after it had already failed to deliver on its contract turned out to be Irimajiri's best decision as Sega's president. After Irimajiri left Sega in 2000, Sega sold its Nvidia stock for $15 million.[38]

In late 1999, Nvidia released the GeForce 256 (NV10), its first product expressly marketed as a GPU, which was most notable for introducing onboard transformation and lighting (T&L) to consumer-level 3D hardware. Running at 120 MHz and featuring four-pixel pipelines, it implemented advanced video acceleration, motion compensation, and hardware sub-picture alpha blending. The GeForce outperformed existing products by a wide margin.

Because its products were performing well, Nvidia won the contract to develop the graphics hardware for Microsoft's Xbox game console, which included a $200 million advance. However, the project took many of its best engineers away from other projects. In the short term this did not matter, and the GeForce 2 GTS shipped in the summer of 2000. In December 2000, Nvidia reached an agreement to acquire the intellectual assets of its one-time rival 3dfx, a pioneer in consumer 3D graphics technology leading the field from the mid-1990s until 2000.[43][44] The acquisition process was finalized in April 2002.[45]

In 2001, Standard & Poor's selected Nvidia to replace the departing Enron in the S&P 500 stock index, meaning that index funds would need to hold Nvidia shares going forward.[46]

In July 2002, Nvidia acquired Exluna for an undisclosed sum. Exluna made software-rendering tools and the personnel were merged into the Cg project.[47] In August 2003, Nvidia acquired MediaQ for approximately US$70 million.[48] It launched GoForce the following year. On April 22, 2004, Nvidia acquired iReady, also a provider of high-performance TCP offload engines and iSCSI controllers.[49] In December 2004, it was announced that Nvidia would assist Sony with the design of the graphics processor (RSX) for the PlayStation 3 game console. On December 14, 2005, Nvidia acquired ULI Electronics, which at the time supplied third-party southbridge parts for chipsets to ATI, Nvidia's competitor.[50] In March 2006, Nvidia acquired Hybrid Graphics.[51] In December 2006, Nvidia, along with its main rival in the graphics industry AMD (which had acquired ATI), received subpoenas from the United States Department of Justice regarding possible antitrust violations in the graphics card industry.[52]

2007-2014
Forbes named Nvidia its Company of the Year for 2007, citing the accomplishments it made during the said period as well as during the previous five years.[53] On January 5, 2007, Nvidia announced that it had completed the acquisition of PortalPlayer, Inc.[54] In February 2008, Nvidia acquired Ageia, developer of PhysX, a physics engine and physics processing unit. Nvidia announced that it planned to integrate the PhysX technology into its future GPU products.[55][56]

In July 2008, Nvidia took a write-down of approximately $200 million on its first-quarter revenue, after reporting that certain mobile chipsets and GPUs produced by the company had "abnormal failure rates" due to manufacturing defects. Nvidia, however, did not reveal the affected products. In September 2008, Nvidia became the subject of a class action lawsuit over the defects, claiming that the faulty GPUs had been incorporated into certain laptop models manufactured by Apple Inc., Dell, and HP. In September 2010, Nvidia reached a settlement, in which it would reimburse owners of the affected laptops for repairs or, in some cases, replacement.[57][58] On January 10, 2011, Nvidia signed a six-year, $1.5 billion cross-licensing agreement with Intel, ending all litigation between the two companies.[59]

In November 2011, after initially unveiling it at Mobile World Congress, Nvidia released its ARM-based system on a chip for mobile devices, Tegra 3. Nvidia claimed that the chip featured the first-ever quad-core mobile CPU.[60][61] In May 2011, it was announced that Nvidia had agreed to acquire Icera, a baseband chip making company in the UK, for $367 million.[62] In January 2013, Nvidia unveiled the Tegra 4, as well as the Nvidia Shield, an Android-based handheld game console powered by the new system on a chip.[63] On July 29, 2013, Nvidia announced that they acquired PGI from STMicroelectronics.[64]

In February 2013, Nvidia announced its plans to build a new headquarters in the form of two giant triangle-shaped buildings on the other side of San Tomas Expressway (to the west of its existing headquarters complex). The company selected triangles as its design theme. As Huang explained in a blog post, the triangle is "the fundamental building block of computer graphics".[65]

In 2014, Nvidia ported the Valve games Portal and Half Life 2 to its Nvidia Shield Tablet as Lightspeed Studio.[66][67] Since 2014, Nvidia has diversified its business focusing on three markets: gaming, automotive electronics, and mobile devices.[68]

That same year, Nvidia also prevailed in litigation brought by the trustee of 3dfx's bankruptcy estate to challenge its 2000 acquisition of 3dfx's intellectual assets. On November 6, 2014, in an unpublished memorandum order, the United States Court of Appeals for the Ninth Circuit affirmed the "district court's judgment affirming the bankruptcy court's determination that [Nvidia] did not pay less than fair market value for assets purchased from 3dfx shortly before 3dfx filed for bankruptcy".[69]

2016-2018
On May 6, 2016, Nvidia unveiled the first GPUs of the GeForce 10 series, the GTX 1080 and 1070, based on the company's new Pascal microarchitecture. Nvidia claimed that both models outperformed its Maxwell-based Titan X model; the models incorporate GDDR5X and GDDR5 memory respectively, and use a 16 nm manufacturing process. The architecture also supports a new hardware feature known as simultaneous multi-projection (SMP), which is designed to improve the quality of multi-monitor and virtual reality (VR) rendering.[70][71][72] Laptops that include these GPUs and are sufficiently thin - as of late 2017, under 0.8 inches (20 mm) - have been designated as meeting Nvidia's "Max-Q" design standard.[73]

In July 2016, Nvidia agreed to a settlement for a false advertising lawsuit regarding its GTX 970 model, as the models were unable to use all of their advertised 4 GB of VRAM due to limitations brought by the design of its hardware.[74] In May 2017, Nvidia announced a partnership with Toyota which would use Nvidia's Drive PX-series artificial intelligence platform for its autonomous vehicles.[75] In July 2017, Nvidia and Chinese search giant Baidu announced a far-reaching AI partnership that includes cloud computing, autonomous driving, consumer devices, and Baidu's open-source AI framework PaddlePaddle. Baidu unveiled that Nvidia's Drive PX 2 AI will be the foundation of its autonomous-vehicle platform.[76]

Nvidia released the Titan V on December 7, 2017.[77][78]

Nvidia released the Nvidia Quadro GV100 on March 27, 2018.[79] Nvidia released the RTX 2080 GPUs on September 27, 2018. In 2018, Google announced that Nvidia's Tesla P4 graphic cards would be integrated into Google Cloud service's artificial intelligence.[80]

In May 2018, on the Nvidia user forum, a thread was started[81] asking the company to update users when they would release web drivers for its cards installed on legacy Mac Pro machines up to mid-2012 5,1 running the macOS Mojave operating system 10.14. Web drivers are required to enable graphics acceleration and multiple display monitor capabilities of the GPU. On its Mojave update info website, Apple stated that macOS Mojave would run on legacy machines with 'Metal compatible' graphics cards[82] and listed Metal compatible GPUs, including some manufactured by Nvidia.[83] However, this list did not include Metal compatible cards that currently work in macOS High Sierra using Nvidia-developed web drivers. In September, Nvidia responded, "Apple fully controls drivers for macOS. But if Apple allows, our engineers are ready and eager to help Apple deliver great drivers for macOS 10.14 (Mojave)."[84] In October, Nvidia followed this up with another public announcement, "Apple fully controls drivers for macOS. Unfortunately, Nvidia currently cannot release a driver unless it is approved by Apple,"[85] suggesting a possible rift between the two companies.[86] By January 2019, with still no sign of the enabling web drivers, Apple Insider weighed into the controversy with a claim that Apple management "doesn't want Nvidia support in macOS".[87] The following month, Apple Insider followed this up with another claim that Nvidia support was abandoned because of "relational issues in the past",[88] and that Apple was developing its own GPU technology.[89] Without Apple-approved Nvidia web drivers, Apple users are faced with replacing their Nvidia cards with a competing supported brand, such as AMD Radeon from the list recommended by Apple.[90]

2019 acquisition of Mellanox Technologies
See also: Mellanox Technologies

Nvidia Yokneam office (former Mellanox Technologies) in Yokneam Illit, Israel, in March 2023
On March 11, 2019, Nvidia announced a deal to buy Mellanox Technologies for $6.9 billion[91] to substantially expand its footprint in the high-performance computing market. In May 2019, Nvidia announced new RTX Studio laptops. The creators say that the new laptop is going to be seven times faster than a top-end MacBook Pro with a Core i9 and AMD's Radeon Pro Vega 20 graphics in apps like Maya and RedCine-X Pro.[92] In August 2019, Nvidia announced Minecraft RTX, an official Nvidia-developed patch for the game Minecraft adding real-time DXR ray tracing exclusively to the Windows 10 version of the game. The whole game is, in Nvidia's words, "refit" with path tracing, which dramatically affects the way light, reflections, and shadows work inside the engine.[93]

2020-2023
In May 2020, Nvidia announced it was acquiring Cumulus Networks.[94] Post acquisition the company was absorbed into Nvidia's networking business unit, along with Mellanox.

In May 2020, Nvidia developed an open-source ventilator to address the shortage resulting from the global coronavirus pandemic.[95] On May 14, 2020, Nvidia officially announced their Ampere GPU microarchitecture and the Nvidia A100 GPU accelerator.[96][97] In July 2020, it was reported that Nvidia was in talks with SoftBank to buy Arm, a UK-based chip designer, for $32 billion.[98]

On September 1, 2020, Nvidia officially announced the GeForce 30 series based on the company's new Ampere microarchitecture.[99][100]

On September 13, 2020, Nvidia announced that they would buy Arm from SoftBank Group for $40 billion, subject to the usual scrutiny, with the latter retaining a 10% share of Nvidia.[101][102][103][104]


Nvidia GeForce RTX 2080 Ti, part of the RTX 20 series, which is the first generation of Nvidia RTX
In October 2020, Nvidia announced its plan to build the most powerful computer in Cambridge, England. The computer, called Cambridge-1, launched in July 2021 with a $100 million investment and will employ AI to support healthcare research.[105][106] According to Jensen Huang, "The Cambridge-1 supercomputer will serve as a hub of innovation for the UK, and further the groundbreaking work being done by the nation's researchers in critical healthcare and drug discovery."[107]

Also in October 2020, along with the release of the Nvidia RTX A6000, Nvidia announced it is retiring its workstation GPU brand Quadro, shifting its product name to Nvidia RTX for future products and the manufacturing to be Nvidia Ampere architecture-based.[108]

In August 2021, the proposed takeover of Arm was stalled after the UK's Competition and Markets Authority raised "significant competition concerns".[109] In October 2021, the European Commission opened a competition investigation into the takeover. The Commission stated that Nvidia's acquisition could restrict competitors' access to Arm's products and provide Nvidia with too much internal information on its competitors due to their deals with Arm. SoftBank (the parent company of Arm) and Nvidia announced in early February 2022 that they "had agreed not to move forward with the transaction 'because of significant regulatory challenges'".[110] The investigation was set to end on March 15, 2022.[111][112] That same month, Nvidia was reportedly compromised by a cyberattack.[113] This would have been the largest semiconductor acquisition in history.[17][18]

In March 2022, Nvidia's CEO Jensen Huang mentioned that they were open to having Intel manufacture their chips in the future.[114] This was the first time the company mentioned that they would work together with Intel's upcoming foundry services.

In April 2022, it was reported that Nvidia planned to open a new research center in Yerevan, Armenia.[115]

In May 2022, Nvidia opened Voyager, the second of the two giant buildings at its new headquarters complex to the west of the old one. Unlike its smaller and older sibling Endeavor, the triangle theming is used more "sparingly" in Voyager.[116][117]

In September 2022, Nvidia announced its next-generation automotive-grade chip, Drive Thor.[118][119]

In September 2022, Nvidia announced a collaboration with the Broad Institute of MIT and Harvard related to the entire suite of Nvidia's AI-powered healthcare software suite called Clara, that includes Parabricks and MONAI.[120]

Following United States Department of Commerce regulations which placed an embargo on exports to China of advanced microchips, which went into effect in October 2022, Nvidia saw its data center chip added to the export control list. The next month, the company unveiled a new advanced chip in China, called the A800 GPU, that met the export control rules.[121]

In September 2023, Getty Images announced that it was partnering with Nvidia to launch Generative AI by Getty Images, a new tool that lets people create images using Getty's library of licensed photos. Getty will use Nvidia's Edify model, which is available on Nvidia's generative AI model library Picasso.[122]

On September 26, 2023, Denny's CEO Kelli Valade joined Huang in East San Jose to celebrate the founding of Nvidia at Denny's on Berryessa Road, where a plaque was installed to mark the relevant corner booth as the birthplace of a $1 trillion company.[27][123] By then, Nvidia's H100 GPUs were in such demand that even other tech giants were beholden to how Nvidia allocated supply. Larry Ellison of Oracle Corporation said that month that during a dinner with Huang at Nobu in Palo Alto, he and Elon Musk of Tesla, Inc. and xAI "were begging" for H100s, "I guess is the best way to describe it. An hour of sushi and begging".[124]

In October 2023, it was reported that Nvidia had quietly begun designing ARM-based central processing units (CPUs) for Microsoft's Windows operating system with a target to start selling them in 2025.[125]

2024-2026
In January 2024, Forbes reported that Nvidia has increased its lobbying presence in Washington, D.C. as American lawmakers consider proposals to regulate artificial intelligence. From 2023 to 2024, the company reportedly hired at least four government affairs with professional backgrounds at agencies including the United States Department of State and the Department of the Treasury. It was noted that the $350,000 spent by the company on lobbying in 2023 was small compared to a number of major tech companies in the artificial intelligence space.[126]

In January 2024, Raymond James Financial analysts estimated that Nvidia was selling the H100 GPU in the price range of $25,000 to $30,000 each, while on eBay, individual H100s cost over $40,000.[127] Several major technology companies were purchasing tens or hundreds of thousands of GPUs for their data centers to run generative artificial intelligence projects; simple arithmetic implied that they were committing to billions of dollars in capital expenditures.[127]

In February 2024, it was reported that Nvidia was the "hot employer" in Silicon Valley because it was offering interesting work and good pay at a time when other tech employers were downsizing. Half of Nvidia employees earned over $228,000 in 2023.[128] By then, Nvidia GPUs had become so valuable that they needed special security while in transit to data centers. Cisco chief information officer Fletcher Previn explained at a CIO summit: "Those GPUs arrive by armored car".[129]

On March 1, 2024, Nvidia became the third company in the history of the United States to close with a market capitalization in excess of $2 trillion.[46] Nvidia needed only 180 days to get to $2 trillion from $1 trillion, while the first two companies, Apple and Microsoft, each took over 500 days.[46] On March 18, Nvidia announced its new AI chip and microarchitecture Blackwell, named after mathematician David Blackwell.[130]

In April 2024, Reuters reported that China had allegedly acquired banned Nvidia chips and servers from Supermicro and Dell via tenders.[131]

In June 2024, the Federal Trade Commission (FTC) and the Justice Department (DOJ) began antitrust investigations into Nvidia, Microsoft and OpenAI, focusing on their influence in the AI industry. The FTC led the investigations into Microsoft and OpenAI, while the DOJ handled Nvidia. The probes centered on the companies' conduct rather than mergers. This development followed an open letter from OpenAI employees expressing concerns about the rapid AI advancements and lack of oversight.[132]

The company became the world's most valuable, surpassing Microsoft and Apple, on June 18, 2024, after its market capitalization exceeded $3.3 trillion.[133][134]

In June 2024, Trend Micro announced a partnership with Nvidia to develop AI-driven security tools, notably to protect the data centers where AI workloads are processed. This collaboration integrates Nvidia NIM and Nvidia Morpheus with Trend Vision One and its Sovereign and Private Cloud solutions to improve data privacy, real-time analysis, and rapid threat mitigation.[135]

In October 2024, Nvidia introduced a family of open-source multimodal large language models called NVLM 1.0, which features a flagship version with 72 billion parameters, designed to improve text-only performance after multimodal training.[136][137]

In November 2024, the company was added to the Dow Jones Industrial Average.[138][139]

In November 2024, Morgan Stanley reported that "the entire 2025 production" of all of Nvidia's Blackwell chips was "already sold out".[140]

Also in November 2024, the company bought 1.2 million shares of Nebius Group.[141]

Nvidia was ranked #3 on Forbes' "Best Places to Work" list in 2024.[142]

As of January 7, 2025, Nvidia's $3.66 trillion market cap was worth more than double of the combined value of AMD, ARM, Broadcom, and Intel.[143]

In January 2025, Nvidia saw the largest one-day loss in market capitalization for a U.S. company in history at $600 billion. This was due to DeepSeek, a Chinese AI startup that developed an advanced AI model at a lower cost and computing power.[144] DeepSeek's AI assistant, using the V3 model, surpassed ChatGPT as the highest-rated free app in the U.S. on Apple's App Store.[145][146]

On April 7, 2025, Nvidia released the Llama-3.1-Nemotron-Ultra-253B-v1 reasoning large language model, under the Nvidia Open Model License. It comes in three sizes: Nano, Super and Ultra.[147]

On May 28, 2025, Nvidia's second-quarter revenue forecast fell short of market estimates due to U.S. export restrictions impacting AI chip sales to China, yet the company's stock rose 5% as investors remained optimistic about long-term AI demand.[148]

In July 2025, it was announced that Nvidia had acquired CentL, a Canadian-based AI firm.[149]

On July 10, 2025, Nvidia closed for the first time with a market cap above $4 trillion, after its market cap briefly touched and then retreated from that number during the previous day.[150] Nvidia became the first company to reach a market cap of $4 trillion.[9] At that point, Nvidia was worth more than the combined value of all publicly traded companies in the United Kingdom.[150]

On July 29, 2025, Nvidia ordered 300,000 H20 AI chips from Taiwan Semiconductor Manufacturing Company (TSMC) due to strong demand from Chinese tech firms like Tencent and Alibaba.[151]

In August 2025, Nvidia and competitor Advanced Micro Devices agreed to pay 15% of the revenues from certain chip sales in China as part of an arrangement to obtain export licenses.[152] Nvidia will pay only for sales of the H20 chips.[153]

On September 17, 2025, Nvidia chief executive Jensen Huang said he was "disappointed" after the Cyberspace Administration of China (CAC) ordered companies including TikTok parent company ByteDance and Alibaba not to purchase the RTX Pro 6000D, a graphics chip made specifically for the Chinese market. China's internet regulator banned the country's largest technology companies from buying Nvidia's artificial intelligence chips as part of efforts to strengthen the domestic industry and compete with the United States. The CAC instructed companies this week to end both testing and orders of the RTX Pro 6000D, which Nvidia had designed as a tailor-made product for China, according to three people with knowledge of the matter.[154][155]

On September 18, 2025, Nvidia announced it would invest $5 billion in Intel, backing the struggling U.S. chipmaker just weeks after the White House arranged a deal for the federal government to take a major stake in the company. The investment will give Nvidia an immediate holding of about 4% in Intel once new shares are issued to finalize the agreement. Nvidia's move provides Intel with fresh support following years of unsuccessful turnaround efforts and will allow Nvidia to offer its powerful GB300 data center servers based on Blackwell GPUs on Intel's X86 architecture.[156]

On September 22, 2025, Nvidia and OpenAI announced a memorandum of understanding for a partnership wherein Nvidia would invest $100 billion into OpenAI, and OpenAI would use Nvidia chips and systems in new data centers. OpenAI will build new AI data centers using Nvidia systems, amounting to at least 10 gigawatts system power, which is the equivalent of energy produced by more than four Hoover Dams. The deal was meant to be a circular arrangement where OpenAI will pay back Nvidia's investment through the purchase of Nvidia's chips, which is a model common in AI partnerships.[157] This "circularity" is estimated at $35 billion in new Nvidia chips bought by OpenAI, for every $10 billion Nvidia invests in OpenAI.[158] As of January 2026, negotiations had not progressed beyond early stages, and the two companies were rethinking the partnership's structure. In the months leading up to this, chief executive Jensen Huang privately emphasized to industry associates that the original deal was non-binding and not finalized when announced.[159]

In October 2025, a coalition of Nvidia, nonprofit Electric Power Research Institute and PJM Interconnection announced that the first commercial application of software--developed by startup Emerald AI (in which Nvidia invests), that adjusts the energy draw on a power grid in real time was to be deployed at a new data center under construction in Virginia. Dubbed "Aurora", the facility is expected to set a new flexible power standard.[160]

A server farm dedicated to autonomous AI was also announced in October 2025, as a collaboration between SDS Sch?nfeld, a data services firm owned by UC Sch?nfeld, and VAST Data, an Israeli company specializing in AI storage management that collaborates closely with Nvidia. Reports indicate that approximately $30 billion has been secured for the Bet Yehoshua server farm. It is expected to feature "tens of petabytes of data infrastructure powered by VAST, along with thousands of Nvidia Blackwell GPUs and Nvidia network processors."[161]

On October 29, 2025, Nvidia became the first company to reach a market capitalization of $5 trillion.[162]

Nvidia's stock prices fell by 2% on November 11, 2025, as the SoftBank Group dumped its entire Nvidia portfolio worth $5.8 billion, redirecting the capital towards OpenAI instead.[163]

On December 1, 2025, Nvidia released Alpamayo-R1, an open source, vision-language-action AI model for self-driving vehicles. This was done so that developers and researchers can understand how these models work and come up with standard ways on how the industry can evaluate how they work.[164]

On December 15, 2025, Nvidia announced the Nemotron 3 family of models consisting of Nano, Super and Ultra models, built on a hybrid mixture-of-experts (MoE) architecture. Nvidia said Nano has around 30 billion parameters, Super 100 billion, and Ultra 500 billion.[165]

On December 18, 2025, Nvidia announced plans to build a major new research and development campus in Kiryat Tivon, Israel, projected to employ more than 10,000 people and become one of the company's largest sites outside the United States. The 22-acre complex is scheduled to begin construction in 2027, with initial operations expected in 2031, and will include laboratories, green areas, and public facilities. The project reinforces Israel's role as Nvidia's principal international development hub in advanced AI and computing technologies.[166]

In December 2025, it was announced that Nvidia had acquired SchedMD, the company behind the open-source workload manager Slurm, as part of an effort to expand its AI and high-performance computing software capabilities. Nvidia stated that Slurm would remain open-source and vendor-neutral after the acquisition, with no financial terms disclosed.[167]

In December 2025, CNBC reported Nvidia had agreed to buy assets from Groq for $20 billion in cash. The deal included a non-exclusive licensing agreement with Nvidia for Groq's inference technology. Several of Groq's senior leaders, including its CEO, also agreed to join Nvidia as part of the deal. While both companies said Groq would continue to operate as an individual company, the transaction drew criticism from several industry analysts as a tactic to avoid regulatory scrutiny.[168][169]

In late 2025, Nvidia entered advanced negotiations to acquire AI21 Labs, an Israeli developer of large language models,[170] in a deal valued at as much as $2 billion to $3 billion.[171][172] The proposed transaction is widely described as a talent-focused "acquihire" aimed at integrating AI21's workforce of approximately 200 specialists into Nvidia's global artificial intelligence operations.[173] If completed, the transaction would be Nvidia's second-largest Israeli acquisition after its $7 billion purchase of Mellanox in 2020.[174]

At CES 2026, CEO Jensen Huang unveiled Nvidia's Vera Rubin AI platform and the Alpamayo open-source model.[175] Hesai was also picked as Nvidia's laser technology partner, supplying Lidar sensors to the company, streamlining software, hardware, and data in its autonomous driving products.[176]

In January 2026, Nvidia launched a new weather forecasting service called Earth-2. It is an open-sourced platform that can be incorporated to improve the AI function across models used by scientists, businesses and local governments.[177]

Corporate affairs
Sales by business unit (2025)[178]
Business unit	Sales (billion $)	Share
Compute & networking	116.2	89.0%
Graphics	14.3	11.0%
Sales by region (2025)[178]
Region	Sales (billion $)	Share
United States	61.3	46.9%
Singapore	23.7	18.2%
Taiwan	20.6	15.8%
China	17.1	13.1%
Other countries	7.9	6.0%
Leadership
Nvidia's key management as of March 2024 consists of:[179]

Jensen Huang, founder, president and chief executive officer
Chris Malachowsky, founder and Nvidia fellow
Colette Kress, executive vice president and chief financial officer
Jay Puri, executive vice president of worldwide field operations
Debora Shoquist, executive vice president of operations
Tim Teter, executive vice president, general counsel and secretary
Board of directors
As of January 2026, the company's board consisted of the following directors:[180]

Tench Coxe (former managing director of Sutter Hill Ventures)
John Dabiri (engineer and professor at the California Institute of Technology)
Jensen Huang (co-founder, CEO and president of Nvidia)
Dawn Hudson (former chief marketing officer of the National Football League)
Harvey C. Jones (managing partner of Square Wave Ventures)
Melissa B. Lora (former president of Taco Bell International)
Stephen Neal (lead independent director of Nvidia, former CEO and chairman emeritus and senior counsel of Cooley LLP)
Brooke Seawell (venture partner at New Enterprise Associates)
Aarti Shah (former senior vice president & chief information and digital officer at Eli Lilly and Company)
Mark Stevens (managing partner at S-Cubed Capital)
Finances

Nvidia stock price (1999-2023)
10-year financials (2016-2025)
Year	Revenue
(mn. US$)	Net income
(mn. US$)	Employees
2016	5,010	614	9,227
2017	6,910	1,666	10,299
2018	9,714	3,047	11,528
2019	11,716	4,141	13,277
2020	10,918	2,796	13,775
2021	16,675	4,332	18,975
2022	26,914	9,752	22,473
2023	26,974	4,368	26,000
2024	60,922	29,760	29,600
2025	130,497	72,880	36,000
For the fiscal year 2020, Nvidia reported earnings of US$2.796 billion, with an annual revenue of US$10.918 billion, a decline of 6.8% over the previous fiscal cycle. Nvidia's shares traded at over $531 per share, and its market capitalization was valued at over US$328.7 billion in January 2021.[181][182]

For the Q2 of 2020, Nvidia reported sales of $3.87 billion, which was a 50% rise from the same period in 2019. The surge in sales and people's higher demand for computer technology. According to the financial chief of the company, Colette Kress, the effects of the pandemic will "likely reflect this evolution in enterprise workforce trends with a greater focus on technologies, such as Nvidia laptops and virtual workstations, that enable remote work and virtual collaboration."[183] In May 2023, Nvidia crossed $1 trillion in market valuation during trading hours,[184] and grew to $1.2 trillion by the following November.[185]

Ownership
The 10 largest shareholders of Nvidia in early 2024 were:[178]

The Vanguard Group (8.280%)
BlackRock (5.623%)
Fidelity Investments (5.161%)
State Street Corporation (3.711%)
Jensen Huang (3.507%)
Geode Capital Management (2.024%)
T. Rowe Price (2.013%)
JPMorgan Chase (1.417%)
BlackRock Life (1.409%)
Eaton Vance (1.337%)
Fabrication
Nvidia uses external suppliers for all phases of manufacturing, including wafer fabrication, assembly, testing, and packaging. Nvidia thus avoids most of the investment and production costs and risks associated with chip manufacturing, although it does sometimes directly procure some components and materials used in the production of its products (e.g., memory and substrates). Nvidia focuses its own resources on product design, quality assurance, marketing, and customer support.[186][187]

GPU Technology Conference
Main article: Nvidia GTC
Nvidia's GPU Technology Conference (GTC) is a series of technical conferences held around the world.[188] It originated in 2009 in San Jose, California, with an initial focus on the potential for solving computing challenges through GPUs.[24] In recent years,[when?] the conference's focus has shifted to various applications of artificial intelligence and deep learning; including self-driving cars, healthcare, high-performance computing, and Nvidia Deep Learning Institute (DLI) training.[189] GTC 2018 attracted over 8400 attendees.[188] GTC 2020 was converted to a digital event and drew roughly 59,000 registrants.[190] After several years of remote-only events, GTC in March 2024 returned to an in-person format in San Jose, California.[191]

At GTC 2025, Nvidia unveiled its next-generation AI hardware, the Blackwell Ultra and Vera Rubin chips, signaling a leap toward agentic AI and reasoning-capable computing. Huang projected that AI-driven infrastructure would drive Nvidia's data center revenue to $1 trillion by 2028. The announcement also introduced Isaac GR00T N1 (humanoid robotics model), Cosmos (synthetic training data AI), and the Newton physics engine, developed in collaboration with DeepMind and Disney Research.[192]

Product families

A Shield Tablet with its accompanying input pen (left) and gamepad
Nvidia's product families include graphics processing units, wireless communication devices, and automotive hardware and software, such as:

GeForce, consumer-oriented graphics processing products
RTX, professional visual computing graphics processing products (replacing GTX and Quadro)
NVS, a multi-display business graphics processor
Tegra, a system on a chip series for mobile devices
Tesla, line of dedicated general-purpose GPUs for high-end image generation applications in professional and scientific fields
nForce, a motherboard chipset created by Nvidia for Intel (Celeron, Pentium and Core 2) and AMD (Athlon and Duron) microprocessors
GRID, a set of hardware and services by Nvidia for graphics virtualization
Shield, a range of gaming hardware including the Shield Portable, Shield Tablet and Shield TV
Drive, a range of hardware and software products for designers and manufacturers of autonomous vehicles. The Drive PX-series is a high-performance computer platform aimed at autonomous driving through deep learning,[193] while Driveworks is an operating system for driverless cars.[194]
BlueField, a range of data processing units, initially inherited from their acquisition of Mellanox Technologies[195][196]
Datacenter/server class CPU, codenamed Grace, released in 2023[197][198]
DGX, an enterprise platform designed for deep learning applications
Maxine, a platform providing developers a suite of AI-based conferencing software[199]
Omniverse, a platform for creating and operating metaverse applications[200]
Open-source software support
See also: Free and open-source graphics device driver, Mesa 3D, and OpenPOWER Foundation
Until September 23, 2013, Nvidia had not published any documentation for its advanced hardware,[201] meaning that programmers could not write free and open-source device drivers for its products without resorting to reverse engineering.

Nvidia has released Linux <open-source GPU kernel modules> under dual GPL/MIT licensing, allowing developers to inspect the driver module code and contribute improvements in collaboration with the community.[1] The Nvidia <open-gpu-kernel-modules repository> on GitHub provides the publicly accessible source code for these modules, supporting modern GPU architectures in Linux environments.[202] Furthermore, Nvidia's acquisition of <SchedMD> and the release of new open-source AI models highlight its broader commitment to open-source software and the AI ecosystem [2]

Instead, Nvidia provides its own binary GeForce graphics drivers for X.Org and an open-source library that interfaces with the Linux, FreeBSD or Solaris kernels and the proprietary graphics software. Nvidia also provided but stopped supporting an obfuscated open-source driver that only supports two-dimensional hardware acceleration and ships with the X.Org distribution.[203]

The proprietary nature of Nvidia's drivers has generated dissatisfaction within free-software communities. In a 2012 talk, Linus Torvalds gave a middle-finger gesture and criticized Nvidia's stance toward Linux.[204][205] Some Linux and BSD users insist on using only open-source drivers and regard Nvidia's insistence on providing nothing more than a binary-only driver as inadequate, given that competing manufacturers such as Intel offer support and documentation for open-source developers, and others like AMD release partial documentation and provide some active development.[206][207]

Nvidia only provides x86/x64 and ARMv7-A versions of their proprietary driver; as a result, features like CUDA are unavailable on other platforms.[208] Some users claim that Nvidia's Linux drivers impose artificial restrictions, like limiting the number of monitors that can be used at the same time, but the company has not commented on these accusations.[209]

In 2014, with its Maxwell GPUs, Nvidia started to require firmware by them to unlock all features of its graphics cards.[210][211][212]

On May 12, 2022, Nvidia announced that they are opensourcing their GPU kernel modules.[213][214][202] Support for Nvidia's firmware was implemented in nouveau in 2023, which allows proper power management and GPU reclocking for Turing and newer graphics card generations.[215][216]

In July 21, 2025, Nvidia announced to extend CUDA support to RISC-V.[217][218][219]

List of Nvidia open-source projects
Nouveau
NVDLA
PhysX
VDPAU
Vibrante
GR00T[220]
garak
Deep learning
Nvidia GPUs are used in deep learning, and accelerated analytics due to Nvidia's CUDA software platform and API which allows programmers to utilize the higher number of cores present in GPUs to parallelize BLAS operations which are extensively used in machine learning algorithms.[11] They were included in many Tesla, Inc. vehicles before Musk announced at Tesla Autonomy Day in 2019 that the company developed its own SoC and full self-driving computer now and would stop using Nvidia hardware for their vehicles.[221][222] These GPUs are used by researchers, laboratories, tech companies and enterprise companies.[223] In 2009, Nvidia was involved in what was called the "big bang" of deep learning, "as deep-learning neural networks were combined with Nvidia graphics processing units (GPUs)".[224] That year, the Google Brain team used Nvidia GPUs to create deep neural networks capable of machine learning, where Andrew Ng determined that GPUs could increase the speed of deep learning systems by about 100 times.[225]

DGX
Main article: Nvidia DGX
DGX is a line of supercomputers by Nvidia.

In April 2016, Nvidia produced the DGX-1 based on an 8 GPU cluster, to improve the ability of users to use deep learning by combining GPUs with integrated deep learning software.[226] Nvidia gifted its first DGX-1 to OpenAI in August 2016 to help it train larger and more complex AI models with the capability of reducing processing time from six days to two hours.[227][228] It also developed Nvidia Tesla K80 and P100 GPU-based virtual machines, which are available through Google Cloud, which Google installed in November 2016.[229] Microsoft added GPU servers in a preview offering of its N series based on Nvidia's Tesla K80s, each containing 4992 processing cores. Later that year, AWS's P2 instance was produced using up to 16 Nvidia Tesla K80 GPUs. That month Nvidia also partnered with IBM to create a software kit that boosts the AI capabilities of Watson,[230] called IBM PowerAI.[231][232] Nvidia also offers its own Nvidia Deep Learning software development kit.[233] In 2017, the GPUs were also brought online at the Riken Center for Advanced Intelligence Project for Fujitsu.[234] The company's deep learning technology led to a boost in its 2017 earnings.[235]

In 2018, Nvidia researchers demonstrated imitation-learning techniques for industrial robots. They have created a system that, after a short revision and testing, can already be used to control the universal robots of the next generation. In addition to GPU manufacturing, Nvidia provides parallel processing capabilities to researchers and scientists that allow them to efficiently run high-performance applications.[236]

Robotics
In 2020, Nvidia unveiled "Omniverse", a virtual environment designed for engineers.[237] Nvidia also open-sourced Isaac Sim, which makes use of this Omniverse to train robots through simulations that mimic the physics of the robots and the real world.[238][239]

In 2024, Huang oriented Nvidia's focus towards humanoid robots and self-driving cars, which he expects to gain widespread adoption.[240][241]

In 2025, Nvidia announced Isaac GR00T N1, an open-source foundation model "designed to expedite the development and capabilities of humanoid robots". Neura Robotics, 1X Technologies and Vention are among the first companies to use the model.[242][243][244]

Inception Program
Nvidia's Inception Program was created to support startups making exceptional advances in the fields of artificial intelligence and data science. Award winners are announced at Nvidia's GTC Conference. In May 2017, the program had 1,300 companies.[245] As of March 2018, there were 2,800 startups in the Inception Program.[246] As of August 2021, the program has over 8,500 members in 90 countries, with cumulative funding of US$60 billion.[247]

Controversies
GTX 970 hardware specifications advertising dispute
Main article: GeForce 900 series ? Advertising controversy
Issues with the GeForce GTX 970's specifications were first brought up by users when they found out that the cards, while featuring 4 GB of memory, rarely accessed memory over the 3.5 GB boundary. Further testing and investigation eventually led to Nvidia issuing a statement that the card's initially announced specifications had been altered without notice before the card was made commercially available, and that the card took a performance hit once memory over the 3.5 GB limit were put into use.[248][249][250]

The card's back-end hardware specifications, initially announced as being identical to those of the GeForce GTX 980, differed in the amount of L2 cache (1.75 MB versus 2 MB in the GeForce GTX 980) and the number of ROPs (56 versus 64 in the 980). Additionally, it was revealed that the card was designed to access its memory as a 3.5 GB section, plus a 0.5 GB one, access to the latter being 7 times slower than the first one.[251] The company then went on to promise a specific driver modification to alleviate the performance issues produced by the cutbacks suffered by the card.[252] However, Nvidia later clarified that the promise had been a miscommunication and there would be no specific driver update for the GTX 970.[253] Nvidia claimed that it would assist customers who wanted refunds in obtaining them.[254] On February 26, 2015, Nvidia CEO Jensen Huang went on record in Nvidia's official blog to apologize for the incident.[255] In February 2015 a class-action lawsuit alleging false advertising was filed against Nvidia and Gigabyte Technology in the United States District Court for the Northern District of California.[256][257]

Nvidia revealed that it is able to disable individual units, each containing 256 KB of L2 cache and 8 ROPs, without disabling whole memory controllers.[258] This comes at the cost of dividing the memory bus into high speed and low speed segments that cannot be accessed at the same time unless one segment is reading while the other segment is writing because the L2/ROP unit managing both of the GDDR5 controllers shares the read return channel and the write data bus between the two GDDR5 controllers and itself.[258] This is used in the GeForce GTX 970, which therefore can be described as having 3.5 GB in its high speed segment on a 224-bit bus and 0.5 GB in a low speed segment on a 32-bit bus.[258]

On July 27, 2016, Nvidia agreed to a preliminary settlement of the U.S. class action lawsuit,[256] offering a $30 refund on GTX 970 purchases. The agreed upon refund represents the portion of the cost of the storage and performance capabilities the consumers assumed they were obtaining when they purchased the card.[259]

GeForce Partner Program
Main article: GeForce Partner Program
The Nvidia GeForce Partner Program was a marketing program designed to provide partnering companies with benefits such as public relations support, video game bundling, and marketing development funds.[260] The program proved to be controversial, with complaints about it possibly being an anti-competitive practice.[261]

First announced in a blog post on March 1, 2018,[262] it was canceled on May 4, 2018.[263]

Hardware Unboxed
On December 10, 2020, Nvidia told YouTube tech reviewer Steven Walton of Hardware Unboxed that it would no longer supply him with GeForce Founders Edition graphics card review units.[264][265] In a Twitter message, Hardware Unboxed said, "Nvidia have officially decided to ban us from receiving GeForce Founders Edition GPU review samples. Their reasoning is that we are focusing on rasterization instead of ray tracing. They have said they will revisit this 'should your editorial direction change.'"[266]

In emails that were disclosed by Walton from Nvidia Senior PR Manager Bryan Del Rizzo, Nvidia had said:

...your GPU reviews and recommendations have continued to focus singularly on rasterization performance, and you have largely discounted all of the other technologies we offer gamers. It is very clear from your community commentary that you do not see things the same way that we, gamers, and the rest of the industry do.[267]

TechSpot, partner site of Hardware Unboxed, said, "this and other related incidents raise serious questions around journalistic independence and what they are expecting of reviewers when they are sent products for an unbiased opinion."[267]

A number of technology reviewers came out strongly against Nvidia's move.[268][269] Linus Sebastian, of Linus Tech Tips, titled the episode of his weekly WAN Show, "NVIDIA might ACTUALLY be EVIL..."[270] and was highly critical of the company's move to dictate specific outcomes of technology reviews.[271] The review site Gamers Nexus said it was, "Nvidia's latest decision to shoot both its feet: They've now made it so that any reviewers covering RT will become subject to scrutiny from untrusting viewers who will suspect subversion by the company. Shortsighted self-own from NVIDIA."[272]

Two days later, Nvidia reversed their stance.[273][274] Hardware Unboxed sent out a Twitter message, "I just received an email from Nvidia apologizing for the previous email & they've now walked everything back."[275][268] On December 14, Hardware Unboxed released a video explaining the controversy from their viewpoint.[276] Via Twitter, they also shared a second apology sent by Nvidia's Del Rizzo that said "to withhold samples because I didn't agree with your commentary is simply inexcusable and crossed the line."[277][278]

Improper disclosures about cryptomining
In 2018, Nvidia's chips became popular for cryptomining, the process of obtaining crypto rewards in exchange for verifying transactions on distributed ledgers, the United States Securities and Exchange Commission (SEC) said. However, the company failed to disclose that it was a "significant element" of its revenue growth from sales of chips designed for gaming, the SEC further added in a statement and charging order. Those omissions misled investors and analysts who were interested in understanding the impact of cryptomining on Nvidia's business, the SEC emphasized. Nvidia, which did not admit or deny the findings, has agreed to pay $5.5 million to settle civil charges, according to a statement made by the SEC in May 2022.[279]

French Competition Authority Investigation
On September 26, 2023, Nvidia's French offices were searched by the French Competition Authority. The raid, authorized by a judge, was part of an investigation into suspected anti-competitive practices in the graphics card sector. Nvidia has not publicly commented on the incident.[280]

AI regulation dispute with Anthropic
In July 2025, a public dispute emerged between Nvidia CEO Jensen Huang and Anthropic CEO Dario Amodei over AI regulation and industry practices. The conflict escalated when Amodei vehemently denied Huang's allegations that he sought to control the AI industry through safety concerns, calling Huang's claims an "outrageous lie."[281] The dispute centered on differing philosophies regarding AI development, with Amodei advocating for stronger regulatory oversight and "responsible scaling policies", while Huang promoted open-source development and criticized what Nvidia characterized as "regulatory capture".[281] Nvidia responded by stating that "lobbying for regulatory capture against open source will only stifle innovation, make AI less safe and secure, and less democratic."[281] The controversy highlighted broader tensions within the AI industry between companies favoring rapid development and those emphasizing safety measures and regulation.[281]

Proposed Shanghai facility
In May 2025, U.S. senators Jim Banks and Elizabeth Warren criticized a proposed Nvidia facility in Shanghai, saying that it "raises significant national security and economic security issues that warrant serious review."[282]

Chinese market halt
In August 2025, Nvidia ordered suppliers to halt production of its H20 AI chip following Chinese government directives warning domestic companies against purchasing the processor due to security concerns.[283][284] The company directed suppliers including Taiwan Semiconductor Manufacturing Company, Samsung Electronics, and Amkor Technology to suspend work on the China-focused processor.[285]

The H20 was developed in late 2023 specifically for the Chinese market to comply with U.S. export restrictions, featuring 96GB of HBM3 memory and 4.0 TB/s memory bandwidth--higher than the H100--but with significantly reduced computational power at 296 TFLOPs compared to the H100's 1979 TFLOPs.[286][287] Despite lower raw performance, the H20 demonstrated over 20% faster performance than the H100 in large language model inference tasks due to architectural optimizations.[286][287]

Prior to the production halt, Nvidia had placed substantial orders for the H20, including 300,000 units from TSMC in July 2025, driven by strong demand from Chinese technology companies.[151] CEO Jensen Huang denied allegations that the H20 contained security backdoors, stating the chips were designed solely for commercial use.[288] The production suspension occurred as Nvidia was developing the B30A, a new chip based on its Blackwell architecture intended to succeed the H20 in the Chinese market.[289]

Following prolonged negotiations, the United States announced in 2026 that it would permit the export of newer H200 chips to China under specified conditions. The move was expected to stimulate market activity. The Chinese market, estimated to be worth hundreds of billions and potentially trillions of U.S. dollars, presents significant profit opportunities for American firms, with revenues reinforcing U.S. leading positions.[290][291]

The decision also drew criticism for simultaneously constraining and strengthening China's technological capabilities, is unreasonable.[292] However, some technology experts argue that China's development capacity has exceeded expectations and warn that the full ban policy could potentially enable real challenges to U.S. influence over technical standard setting.[293][294] China also quickly responded by imposing restrictions on certain foreign chips to be imported.[295] Despite China's efforts to shape technical standards, still, American products and ecosystem retain strong appeal, raising government concerns over possible fragmentation and reduced reinvestment in their own artificial intelligence progress.[296] More broadly, China is seen as seeking long-term influence to counterbalance the United States rather than maintaining competitive complementarity rival.[297]

Data scraping & Anna's Archive piracy
Nvidia has been involved in heavy data scraping for AI model training. In January 2026, a court filing revealed that Nvidia developers contacted shadow library Anna's Archive to evaluate the use of pirated content for model training, which management gave green light for despite legality concerns from the site.[298]